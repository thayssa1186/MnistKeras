{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnistcnnkeras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/thayssa1186/MnistKeras/blob/master/mnistcnnkeras.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "DU_HvmeAeC9g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "14f01c16-6816-4e9d-e84e-c6465bc24c16"
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.models import model_from_json"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ygSisyyXe2-g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xg8udpmyfEsY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (5, 5), input_shape=(1, 28, 28), activation='relu', data_format='channels_first'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XtHLNEnSfLnL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filepath=\"weights.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "# check 5 epochs\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, mode='min') \n",
        "\n",
        "callbacks_list = [checkpoint, early_stop]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LgWvaoH7fSyj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1058
        },
        "outputId": "52423c30-5dba-4e90-9162-6d3f73c19dc4"
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test),  epochs=150, batch_size=128,  verbose=2, callbacks=callbacks_list)\n",
        "\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/150\n",
            " - 163s - loss: 0.2134 - acc: 0.9372 - val_loss: 0.0713 - val_acc: 0.9785\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.07131, saving model to weights.best.hdf5\n",
            "Epoch 2/150\n",
            " - 162s - loss: 0.0706 - acc: 0.9780 - val_loss: 0.0490 - val_acc: 0.9840\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.07131 to 0.04902, saving model to weights.best.hdf5\n",
            "Epoch 3/150\n",
            " - 162s - loss: 0.0505 - acc: 0.9846 - val_loss: 0.0418 - val_acc: 0.9861\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.04902 to 0.04184, saving model to weights.best.hdf5\n",
            "Epoch 4/150\n",
            " - 162s - loss: 0.0404 - acc: 0.9871 - val_loss: 0.0353 - val_acc: 0.9879\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.04184 to 0.03526, saving model to weights.best.hdf5\n",
            "Epoch 5/150\n",
            " - 162s - loss: 0.0330 - acc: 0.9894 - val_loss: 0.0323 - val_acc: 0.9900\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.03526 to 0.03232, saving model to weights.best.hdf5\n",
            "Epoch 6/150\n",
            " - 162s - loss: 0.0257 - acc: 0.9920 - val_loss: 0.0362 - val_acc: 0.9878\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.03232\n",
            "Epoch 7/150\n",
            " - 162s - loss: 0.0210 - acc: 0.9935 - val_loss: 0.0443 - val_acc: 0.9862\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.03232\n",
            "Epoch 8/150\n",
            " - 162s - loss: 0.0181 - acc: 0.9942 - val_loss: 0.0458 - val_acc: 0.9856\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.03232\n",
            "Epoch 9/150\n",
            " - 161s - loss: 0.0166 - acc: 0.9946 - val_loss: 0.0360 - val_acc: 0.9885\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.03232\n",
            "Epoch 10/150\n",
            " - 162s - loss: 0.0124 - acc: 0.9961 - val_loss: 0.0306 - val_acc: 0.9904\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.03232 to 0.03058, saving model to weights.best.hdf5\n",
            "Epoch 11/150\n",
            " - 162s - loss: 0.0117 - acc: 0.9959 - val_loss: 0.0328 - val_acc: 0.9904\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.03058\n",
            "Epoch 12/150\n",
            " - 163s - loss: 0.0093 - acc: 0.9971 - val_loss: 0.0401 - val_acc: 0.9888\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.03058\n",
            "Epoch 13/150\n",
            " - 163s - loss: 0.0094 - acc: 0.9967 - val_loss: 0.0346 - val_acc: 0.9895\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.03058\n",
            "Epoch 14/150\n",
            " - 162s - loss: 0.0078 - acc: 0.9975 - val_loss: 0.0381 - val_acc: 0.9896\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.03058\n",
            "Epoch 15/150\n",
            " - 162s - loss: 0.0068 - acc: 0.9978 - val_loss: 0.0414 - val_acc: 0.9894\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.03058\n",
            "acc: 98.94%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y1QFWC46ss05",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2b9a9a6c-798a-44cd-ecbf-7c9a0f4f6c75"
      },
      "cell_type": "code",
      "source": [
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JPGIoTMGsvN7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "324db6d8-44f0-4c8a-e391-1561f7240444"
      },
      "cell_type": "code",
      "source": [
        "# load json and create model\n",
        "json_file = open('model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model.h5\")\n",
        "print(\"Loaded model from disk\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "trMm5pcJtWV4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "6b5d6857-0567-47eb-aea1-12e3e5b479e2"
      },
      "cell_type": "code",
      "source": [
        "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "# calculate predictions\n",
        "#predictions = loaded_model.predict(X_test)\n",
        "#y_classes = predictions.argmax(axis=-1)\n",
        "\n",
        "preds = loaded_model.predict_classes(X_test)\n",
        "prob = loaded_model.predict_proba(X_test)\n",
        "\n",
        "# evaluate the model\n",
        "scores = loaded_model.evaluate(X_test, y_test)\n",
        "print(\"\\n%s: %.2f%%\" % (loaded_model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 17s 2ms/step\n",
            "\n",
            "acc: 99.79%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}